{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6a3d8cd-eff1-43f9-bbef-5d6477592543",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# HR Policy and Tool-Calling Agent\n",
    "\n",
    "## Overview\n",
    "AI agent using tool-calling to analyze HR policies and evaluate employee promotion eligibility. Processes employee data from **SAP SuccessFactors Data Products** to provide actionable insights.\n",
    "\n",
    "## Key Components\n",
    "\n",
    "### 1. Tool-Calling Architecture\n",
    "- **Purpose**: Enables the AI to dynamically select and execute appropriate tools/functions\n",
    "- **Benefits**: \n",
    "  - More accurate responses by accessing real-time data\n",
    "  - Modular and extensible design\n",
    "  - Better control over AI behavior\n",
    "\n",
    "### 2. HR Policy Integration\n",
    "- **Policy Database**: Centralized repository of company HR policies\n",
    "- **Query Interface**: Natural language interface for policy questions\n",
    "- **Context Awareness**: Agent understands employee context and role-specific policies\n",
    "\n",
    "### 3. Agent Workflow\n",
    "1. **Question Parsing**: Understands user intent and required information\n",
    "2. **Tool Selection**: Chooses appropriate tools (policy lookup, employee data, etc.)\n",
    "3. **Execution**: Runs selected tools with proper parameters\n",
    "4. **Response Generation**: Synthesizes results into clear, actionable answers\n",
    "\n",
    "## Use Cases\n",
    "- Policy clarification requests\n",
    "- Career path recommendations\n",
    "- Compliance verification\n",
    "- Employee eligibility checks\n",
    "- Benefits and leave policy queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Install required packages and import libraries for PDF parsing and Spark operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df4787bf-11ab-42ca-85d5-06b7bfb41187",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Install the correct package in a notebook cell\n",
    "%pip install pymupdf\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "import pymupdf as fitz  # PyMuPDF for PDF parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "Load employee and performance data from SAP SuccessFactors Data Products, then transform and enrich the dataset with performance ratings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2779bc44-519c-4be4-948d-2ab5946b0e3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load data from SAP SuccessFactors Data Products\n",
    "print(\"ðŸ“Š Loading SAP SuccessFactors BDC data from Data Products...\")\n",
    "\n",
    "# Load from SAP SuccessFactors Data Products using spark.sql (fast Databricks loading)\n",
    "employees_df_raw = spark.sql(\n",
    "    \"SELECT * FROM core_workforce_data_dp.coreworkforcedata.coreworkforce_standardfields\"\n",
    ")\n",
    "\n",
    "performance_df_raw = spark.sql(\n",
    "    \"SELECT * FROM performance_reviews_dp.performancereviews.commentfeedback\"\n",
    ")\n",
    "\n",
    "# Map columns to expected names (keep original structure, just add aliases)\n",
    "employees_df = employees_df_raw.select(\n",
    "    F.col(\"userId\").alias(\"employee_id\"),\n",
    "    F.col(\"age\"),\n",
    "    F.col(\"gender\"),\n",
    "    F.col(\"department\"),\n",
    "    F.col(\"jobTitle\").alias(\"job_title\"),\n",
    "    F.when(F.col(\"jobTitle\").rlike(\"Manager|Director|VP|Chief\"), 3)\n",
    "     .when(F.col(\"jobTitle\").rlike(\"Senior|Lead|Principal|Staff\"), 2)\n",
    "     .otherwise(1).alias(\"job_level\"),\n",
    "    F.col(\"location\"),\n",
    "    F.col(\"employmentType\").alias(\"employment_type\"),\n",
    "    F.col(\"annualSalary\").alias(\"base_salary\"),\n",
    "    (F.col(\"totalOrgTenureCalc\") / 30).cast(\"int\").alias(\"tenure_months\"),\n",
    "    (F.col(\"totalPositionTenureCalc\") / 30).cast(\"int\").alias(\"months_in_current_role\"),\n",
    "    F.col(\"employmentStatus\").alias(\"employment_status\"),\n",
    "    F.lit(\"Unknown\").alias(\"first_name\"),  # Add default if not in source\n",
    "    F.lit(\"Unknown\").alias(\"last_name\")    # Add default if not in source\n",
    ")\n",
    "\n",
    "# Process performance data\n",
    "performance_df = performance_df_raw.select(\n",
    "    F.col(\"subject_8995a2862a8343bd8390aaa82c46e881\").alias(\"employee_id\"),\n",
    "    F.col(\"modifiedAt\").alias(\"review_date\"),\n",
    "    F.col(\"numberValue\").alias(\"overall_rating\"),\n",
    "    F.col(\"numberValue\").alias(\"competency_rating\"),\n",
    "    (F.col(\"numberValue\") * 20).cast(\"int\").alias(\"goals_achievement\"),\n",
    "    F.col(\"id\").cast(\"string\").alias(\"review_id\")\n",
    ").filter(F.col(\"numberValue\").isNotNull() & (F.col(\"numberValue\") > 0))\n",
    "\n",
    "# Get latest performance rating for each employee\n",
    "latest_performance = performance_df.withColumn(\n",
    "    \"row_num\",\n",
    "    F.row_number().over(\n",
    "        Window.partitionBy(\"employee_id\")\n",
    "        .orderBy(F.col(\"review_date\").desc())\n",
    "    )\n",
    ").filter(F.col(\"row_num\") == 1).drop(\"row_num\")\n",
    "\n",
    "# Join employees with latest performance data to create enriched dataset\n",
    "df_employees = employees_df.alias(\"e\").join(\n",
    "    latest_performance.alias(\"p\"),\n",
    "    F.col(\"e.employee_id\") == F.col(\"p.employee_id\"),\n",
    "    \"left\"\n",
    ").select(\n",
    "    F.col(\"e.employee_id\").alias(\"EmployeeID\"),\n",
    "    F.col(\"e.first_name\").alias(\"Name\"),  # Use first_name from employees_df\n",
    "    F.col(\"e.department\").alias(\"Department\"),\n",
    "    F.col(\"e.months_in_current_role\").alias(\"YearsInDepartment\"),  # Using months as years for compatibility\n",
    "    F.coalesce(F.col(\"p.overall_rating\") * 20, F.lit(70)).alias(\"PerformanceScore\"),  # Convert rating (1-5) to score (20-100)\n",
    "    F.lit(False).alias(\"AlreadyPromoted\")  # Default to False, can be updated based on actual data\n",
    ")\n",
    "\n",
    "# Save as a permanent Delta table in Unity Catalog\n",
    "df_employees.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(\"workspace.default.employee_details\")\n",
    "\n",
    "print(f\"âœ… Data loaded: {df_employees.count():,} employees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Document Extraction\n",
    "Extract text from the HR promotion policy PDF document for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "395c7052-68d2-4e96-a877-fa09f563b4f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# save employee dataframe as a table (for backward compatibility with existing queries)\n",
    "df_employees.write.mode(\"overwrite\").saveAsTable(\"default.employee_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Rule Extraction\n",
    "Use LLM to parse the policy document and extract structured promotion rules (minimum months, performance cycles, exceptions) as JSON.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39dd792d-01df-406a-b853-89e9caa6d423",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# UPDATE PATH TO WHERE THE POLICY PDF TEXT IS STORED\n",
    "pdf_path = \"/Workspace/Users/jing.wen.wang@sap.com/HR Policy into Actionable Promotion Insights/Employee-Promotion-SOP-Samples.pdf\"  \n",
    "\n",
    "with fitz.open(pdf_path) as doc:\n",
    "    policy_text = \"\"\n",
    "    for page in doc:\n",
    "        policy_text += page.get_text()\n",
    "\n",
    "# Optionally, preview the extracted text\n",
    "print(policy_text[:1000])  # Show first 1000 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Policy Rules\n",
    "Store extracted policy rules in a Spark table for programmatic access.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1474bde5-75a5-4674-805b-23088322ddf4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Section 3: Ask LLM for JSON Directly ---\n",
    "LLM_ENDPOINT_NAME = \"databricks-meta-llama-3-3-70b-instruct\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are an AI assistant specializing in HR promotion policy analysis.\n",
    "\n",
    "Read the promotion policy below and extract these values into a JSON object:\n",
    "- min_months_in_position (integer, months required in department before promotion)\n",
    "- min_performance_cycles (integer, number of recent review cycles with high performance)\n",
    "- exceptions (list of strings)\n",
    "\n",
    "If a value is not explicitly stated, set it to null or an empty list.\n",
    "\n",
    "Return only valid JSON â€” no explanations, no extra text.\n",
    "\n",
    "Policy:\n",
    "\\\"\\\"\\\"\n",
    "{policy_text}\n",
    "\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "safe_prompt = prompt.replace(\"'\", \"''\")\n",
    "\n",
    "sql_query = f\"\"\"\n",
    "SELECT ai_query('{LLM_ENDPOINT_NAME}', '{safe_prompt}') AS promotion_policy_json\n",
    "\"\"\"\n",
    "result_df = spark.sql(sql_query)\n",
    "raw_output = result_df.collect()[0][\"promotion_policy_json\"].strip()\n",
    "\n",
    "# Clean JSON if wrapped in markdown fences\n",
    "if raw_output.startswith(\"```\"):\n",
    "    raw_output = raw_output.strip(\"`\").replace(\"json\", \"\", 1).strip()\n",
    "\n",
    "import json\n",
    "try:\n",
    "    policy_dict = json.loads(raw_output)\n",
    "except json.JSONDecodeError:\n",
    "    # Fallback in case model doesn't follow instructions\n",
    "    policy_dict = {\n",
    "        \"min_months_in_position\": None,\n",
    "        \"min_performance_cycles\": None,\n",
    "        \"exceptions\": []\n",
    "    }\n",
    "\n",
    "print(\"\\n=== Parsed JSON from LLM ===\\n\", json.dumps(policy_dict, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Promotion Eligibility Function\n",
    "Create a SQL function that evaluates employee promotion eligibility based on tenure, performance cycles, and performance plan status.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "018dc7b5-bd86-4eb2-b38c-e9b2f929e66e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>min_months_in_position</th><th>min_performance_cycles</th><th>exceptions</th></tr></thead><tbody><tr><td>3</td><td>2</td><td>[\"Managers' subjective opinions unsupported by performance evaluations or metrics\", \"Discrimination\", \"Fraternization\", \"Favoritism\", \"Nepotism\"]</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         3,
         2,
         "[\"Managers' subjective opinions unsupported by performance evaluations or metrics\", \"Discrimination\", \"Fraternization\", \"Favoritism\", \"Nepotism\"]"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "min_months_in_position",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "min_performance_cycles",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "exceptions",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Section 4: Save JSON to Spark Table ---\n",
    "from pyspark.sql import Row\n",
    "\n",
    "policy_row = Row(\n",
    "    min_months_in_position = policy_dict.get(\"min_months_in_position\") or 0,\n",
    "    min_performance_cycles = policy_dict.get(\"min_performance_cycles\") or 0,\n",
    "    exceptions = json.dumps(policy_dict.get(\"exceptions\", []))\n",
    ")\n",
    "\n",
    "policy_df = spark.createDataFrame([policy_row])\n",
    "policy_df.write.mode(\"overwrite\").saveAsTable(\"workspace.default.promotion_policy_rules\")\n",
    "display(policy_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI-Powered Validation Function\n",
    "Create a tool-calling function that uses AI to validate employee records and identify potential issues or missing information for promotion eligibility assessment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dec93768-2f5a-42f2-9292-a1c73f284c93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION workspace.default.is_employee_eligible_for_promotion(\n",
    "  months_in_position INT,\n",
    "  high_perf_cycles INT,\n",
    "  under_performance_plan BOOLEAN\n",
    ")\n",
    "RETURNS BOOLEAN\n",
    "RETURN (\n",
    "  SELECT\n",
    "    CASE\n",
    "      WHEN months_in_position < (\n",
    "        SELECT COALESCE(min_months_in_position, 0)\n",
    "        FROM workspace.default.promotion_policy_rules\n",
    "        LIMIT 1\n",
    "      ) THEN FALSE\n",
    "      WHEN high_perf_cycles < (\n",
    "        SELECT COALESCE(min_performance_cycles, 0)\n",
    "        FROM workspace.default.promotion_policy_rules\n",
    "        LIMIT 1\n",
    "      ) THEN FALSE\n",
    "      WHEN under_performance_plan = TRUE THEN FALSE\n",
    "      ELSE TRUE\n",
    "    END\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3254bf1d-b995-4137-9eb0-75dc5756a551",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION workspace.default.dox_validate_employee_promotion(employee_id STRING)\n",
    "RETURNS STRING\n",
    "RETURN (\n",
    "  SELECT ai_query(\n",
    "    'databricks-claude-3-7-sonnet',\n",
    "    CONCAT(\n",
    "      'You are a senior HR analyst reviewing employee promotion eligibility.\\n\\n',\n",
    "      'Please analyze the completeness and consistency of the following employee record (ID: ', CAST(MAX(EmployeeID) AS STRING), ').\\n',\n",
    "      'Employee fields:\\n',\n",
    "      '- Name: ', COALESCE(MAX(Name), 'NULL'), '\\n',\n",
    "      '- Department: ', COALESCE(MAX(Department), 'NULL'), '\\n',\n",
    "      '- YearsInDepartment: ', COALESCE(CAST(MAX(YearsInDepartment) AS STRING), 'NULL'), '\\n',\n",
    "      '- PerformanceScore: ', COALESCE(CAST(MAX(PerformanceScore) AS STRING), 'NULL'), '\\n',\n",
    "      '- AlreadyPromoted: ', COALESCE(CAST(MAX(AlreadyPromoted) AS STRING), 'NULL'), '\\n\\n',\n",
    "      'Instructions:\\n',\n",
    "      '1. Identify any missing or suspicious data fields.\\n',\n",
    "      '2. Highlight any potential reasons why the employee might not be eligible for promotion.\\n',\n",
    "      '3. Suggest additional checks or data fields that could improve the promotion eligibility assessment.\\n\\n',\n",
    "      'Respond as 3-5 clear bullet points.'\n",
    "    )\n",
    "  )\n",
    "  FROM workspace.default.employee_details\n",
    "  WHERE EmployeeID = CAST(employee_id AS INT)\n",
    ");"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5406832553763528,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "HR Policy and Tool-Calling Agent",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
